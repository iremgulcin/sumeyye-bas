{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Developing Text Classification Model Using BERT for Fake News Detection"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:09.171994Z","iopub.status.busy":"2023-12-03T22:00:09.171753Z","iopub.status.idle":"2023-12-03T22:00:15.669065Z","shell.execute_reply":"2023-12-03T22:00:15.668281Z","shell.execute_reply.started":"2023-12-03T22:00:09.171971Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import os\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:15.671301Z","iopub.status.busy":"2023-12-03T22:00:15.670801Z","iopub.status.idle":"2023-12-03T22:00:15.946273Z","shell.execute_reply":"2023-12-03T22:00:15.945510Z","shell.execute_reply.started":"2023-12-03T22:00:15.671268Z"},"trusted":true},"outputs":[],"source":["DATA_FILE = 'data/politifact_factcheck_data.json'\n","df = pd.read_json(DATA_FILE, lines=True)\n","# Binarize the labels\n","binary_map = {\n","    'true': 1,\n","    'mostly-true': 1, \n","    'half-true': 1,\n","    'mostly-false': 0,\n","    'false': 0,\n","    'pants-fire': 0 \n","}\n","\n","df['label'] = df['verdict'].map(binary_map)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:15.947556Z","iopub.status.busy":"2023-12-03T22:00:15.947302Z","iopub.status.idle":"2023-12-03T22:00:15.952137Z","shell.execute_reply":"2023-12-03T22:00:15.951285Z","shell.execute_reply.started":"2023-12-03T22:00:15.947533Z"},"trusted":true},"outputs":[],"source":["# Create sentence and label lists\n","sentences = df.statement.values\n","labels = df.label.values"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:15.954426Z","iopub.status.busy":"2023-12-03T22:00:15.954145Z","iopub.status.idle":"2023-12-03T22:00:15.961606Z","shell.execute_reply":"2023-12-03T22:00:15.960704Z","shell.execute_reply.started":"2023-12-03T22:00:15.954403Z"},"trusted":true},"outputs":[],"source":["class TextClassificationDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","    def __len__(self):\n","        return len(self.texts)\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n","        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:36.733107Z","iopub.status.busy":"2023-12-03T22:00:36.732363Z","iopub.status.idle":"2023-12-03T22:00:36.742024Z","shell.execute_reply":"2023-12-03T22:00:36.740863Z","shell.execute_reply.started":"2023-12-03T22:00:36.733075Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","from transformers import BertModel\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self, bert_model_name, num_classes, dropout_prob=0.1):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = BertModel.from_pretrained(bert_model_name)\n","        self.dropout = nn.Dropout(dropout_prob)\n","        \n","        # Custom head with additional layers\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.bert.config.hidden_size, 512),  # Adjust the size as needed\n","            nn.ReLU(),  # You can also try other activation functions\n","            nn.LayerNorm(512),  # Add layer normalization\n","            nn.Dropout(dropout_prob),\n","            nn.Linear(512, num_classes)\n","        )\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n","        \n","        # Use the last layer's output instead of the pooler output\n","        last_hidden_states = outputs.last_hidden_state\n","        pooled_output = last_hidden_states.mean(dim=1)  # You can use mean pooling\n","        \n","        x = self.dropout(pooled_output)\n","        logits = self.fc(x)\n","        \n","        return logits\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:37.252159Z","iopub.status.busy":"2023-12-03T22:00:37.251865Z","iopub.status.idle":"2023-12-03T22:00:37.258507Z","shell.execute_reply":"2023-12-03T22:00:37.257608Z","shell.execute_reply.started":"2023-12-03T22:00:37.252136Z"},"trusted":true},"outputs":[],"source":["def train(model, data_loader, optimizer, scheduler, device):\n","    model.train()\n","    for batch in data_loader:\n","        optimizer.zero_grad()\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        labels = batch['label'].to(device)\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        loss = nn.CrossEntropyLoss()(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:37.614443Z","iopub.status.busy":"2023-12-03T22:00:37.614159Z","iopub.status.idle":"2023-12-03T22:00:37.621049Z","shell.execute_reply":"2023-12-03T22:00:37.620169Z","shell.execute_reply.started":"2023-12-03T22:00:37.614420Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, data_loader, device):\n","    model.eval()\n","    predictions = []\n","    actual_labels = []\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['label'].to(device)\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            _, preds = torch.max(outputs, dim=1)\n","            predictions.extend(preds.cpu().tolist())\n","            actual_labels.extend(labels.cpu().tolist())\n","    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:37.932228Z","iopub.status.busy":"2023-12-03T22:00:37.931948Z","iopub.status.idle":"2023-12-03T22:00:37.938316Z","shell.execute_reply":"2023-12-03T22:00:37.937314Z","shell.execute_reply.started":"2023-12-03T22:00:37.932205Z"},"trusted":true},"outputs":[],"source":["def predict_verdict(text, model, tokenizer, device, max_length=128):\n","    model.eval()\n","    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n","    input_ids = encoding['input_ids'].to(device)\n","    attention_mask = encoding['attention_mask'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        _, preds = torch.max(outputs, dim=1)\n","        return \"true\" if preds.item() == 1 else \"fake\""]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:38.228920Z","iopub.status.busy":"2023-12-03T22:00:38.228637Z","iopub.status.idle":"2023-12-03T22:00:38.233262Z","shell.execute_reply":"2023-12-03T22:00:38.232328Z","shell.execute_reply.started":"2023-12-03T22:00:38.228897Z"},"trusted":true},"outputs":[],"source":["# Set up parameters\n","bert_model_name = 'bert-base-cased'\n","num_classes = 2\n","max_length = 128\n","batch_size = 16\n","num_epochs = 2\n","learning_rate = 2e-5"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:39.173811Z","iopub.status.busy":"2023-12-03T22:00:39.173426Z","iopub.status.idle":"2023-12-03T22:00:39.181144Z","shell.execute_reply":"2023-12-03T22:00:39.179912Z","shell.execute_reply.started":"2023-12-03T22:00:39.173781Z"},"trusted":true},"outputs":[],"source":["train_texts, val_texts, train_labels, val_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:39.183631Z","iopub.status.busy":"2023-12-03T22:00:39.183022Z","iopub.status.idle":"2023-12-03T22:00:39.345789Z","shell.execute_reply":"2023-12-03T22:00:39.344992Z","shell.execute_reply.started":"2023-12-03T22:00:39.183598Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n","train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n","val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:40.015799Z","iopub.status.busy":"2023-12-03T22:00:40.015067Z","iopub.status.idle":"2023-12-03T22:00:45.701761Z","shell.execute_reply":"2023-12-03T22:00:45.700944Z","shell.execute_reply.started":"2023-12-03T22:00:40.015767Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b392c932b1f2464da4f7f5652eaabc3e","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = BERTClassifier(bert_model_name, num_classes).to(device)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:45.704036Z","iopub.status.busy":"2023-12-03T22:00:45.703666Z","iopub.status.idle":"2023-12-03T22:00:45.714822Z","shell.execute_reply":"2023-12-03T22:00:45.713919Z","shell.execute_reply.started":"2023-12-03T22:00:45.704004Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["optimizer = AdamW(model.parameters(), lr=learning_rate)\n","total_steps = len(train_dataloader) * num_epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:00:45.716682Z","iopub.status.busy":"2023-12-03T22:00:45.716302Z","iopub.status.idle":"2023-12-03T22:08:15.572358Z","shell.execute_reply":"2023-12-03T22:08:15.571418Z","shell.execute_reply.started":"2023-12-03T22:00:45.716657Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","Validation Accuracy: 0.6849\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.68      0.71      2352\n","           1       0.63      0.69      0.66      1879\n","\n","    accuracy                           0.68      4231\n","   macro avg       0.68      0.69      0.68      4231\n","weighted avg       0.69      0.68      0.69      4231\n","\n","Epoch 2/2\n","Validation Accuracy: 0.6878\n","              precision    recall  f1-score   support\n","\n","           0       0.76      0.63      0.69      2352\n","           1       0.62      0.75      0.68      1879\n","\n","    accuracy                           0.69      4231\n","   macro avg       0.69      0.69      0.69      4231\n","weighted avg       0.70      0.69      0.69      4231\n","\n"]}],"source":["for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","    train(model, train_dataloader, optimizer, scheduler, device)\n","    accuracy, report = evaluate(model, val_dataloader, device)\n","    print(f\"Validation Accuracy: {accuracy:.4f}\")\n","    print(report)"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-03T22:08:33.549834Z","iopub.status.busy":"2023-12-03T22:08:33.548937Z","iopub.status.idle":"2023-12-03T22:08:34.481278Z","shell.execute_reply":"2023-12-03T22:08:34.480270Z","shell.execute_reply.started":"2023-12-03T22:08:33.549801Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), \"model/bert_classifier.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4100851,"sourceId":7111908,"sourceType":"datasetVersion"}],"dockerImageVersionId":30589,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
