{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7111908,"sourceType":"datasetVersion","datasetId":4100851}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Developing Text Classification Model Using BERT for Fake News Detection","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:22:43.752245Z","iopub.execute_input":"2023-12-03T13:22:43.752523Z","iopub.status.idle":"2023-12-03T13:22:50.120687Z","shell.execute_reply.started":"2023-12-03T13:22:43.752497Z","shell.execute_reply":"2023-12-03T13:22:50.119936Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_FILE = 'data/politifact_factcheck_data.json'\ndf = pd.read_json(DATA_FILE, lines=True)\n# Binarize the labels\nbinary_map = {\n    'true': 1,\n    'mostly-true': 1, \n    'half-true': 1,\n    'mostly-false': 0,\n    'false': 0,\n    'pants-fire': 0 \n}\n\ndf['label'] = df['verdict'].map(binary_map)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:22:50.122154Z","iopub.execute_input":"2023-12-03T13:22:50.122569Z","iopub.status.idle":"2023-12-03T13:22:50.458622Z","shell.execute_reply.started":"2023-12-03T13:22:50.122542Z","shell.execute_reply":"2023-12-03T13:22:50.457857Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Create sentence and label lists\nsentences = df.statement.values\nlabels = df.label.values","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:22:50.460070Z","iopub.execute_input":"2023-12-03T13:22:50.460486Z","iopub.status.idle":"2023-12-03T13:22:50.465167Z","shell.execute_reply.started":"2023-12-03T13:22:50.460448Z","shell.execute_reply":"2023-12-03T13:22:50.464274Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class TextClassificationDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    def __len__(self):\n        return len(self.texts)\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:22:50.468053Z","iopub.execute_input":"2023-12-03T13:22:50.468416Z","iopub.status.idle":"2023-12-03T13:22:50.476364Z","shell.execute_reply.started":"2023-12-03T13:22:50.468384Z","shell.execute_reply":"2023-12-03T13:22:50.475470Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import BertModel\n\nclass BERTClassifier(nn.Module):\n    def __init__(self, bert_model_name, num_classes, dropout_prob=0.1):\n        super(ModifiedBERTClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(bert_model_name)\n        self.dropout = nn.Dropout(dropout_prob)\n        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        \n        # Use the last layer's output instead of the pooler output\n        last_hidden_states = outputs.last_hidden_state\n        pooled_output = last_hidden_states.mean(dim=1)  # You can use mean pooling\n        \n        x = self.dropout(pooled_output)\n        logits = self.fc(x)\n        \n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:25:23.307977Z","iopub.execute_input":"2023-12-03T16:25:23.308369Z","iopub.status.idle":"2023-12-03T16:25:23.316288Z","shell.execute_reply.started":"2023-12-03T16:25:23.308334Z","shell.execute_reply":"2023-12-03T16:25:23.315060Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"def train(model, data_loader, optimizer, scheduler, device):\n    model.train()\n    for batch in data_loader:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        loss = nn.CrossEntropyLoss()(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:22:50.487523Z","iopub.execute_input":"2023-12-03T13:22:50.487780Z","iopub.status.idle":"2023-12-03T13:22:50.496386Z","shell.execute_reply.started":"2023-12-03T13:22:50.487756Z","shell.execute_reply":"2023-12-03T13:22:50.495560Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            _, preds = torch.max(outputs, dim=1)\n            predictions.extend(preds.cpu().tolist())\n            actual_labels.extend(labels.cpu().tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:22:50.497502Z","iopub.execute_input":"2023-12-03T13:22:50.497811Z","iopub.status.idle":"2023-12-03T13:22:50.507952Z","shell.execute_reply.started":"2023-12-03T13:22:50.497787Z","shell.execute_reply":"2023-12-03T13:22:50.507194Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def predict_verdict(text, model, tokenizer, device, max_length=128):\n    model.eval()\n    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n    input_ids = encoding['input_ids'].to(device)\n    attention_mask = encoding['attention_mask'].to(device)\n\n    with torch.no_grad():\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n        return \"true\" if preds.item() == 1 else \"fake\"","metadata":{"execution":{"iopub.status.busy":"2023-12-03T13:22:50.508979Z","iopub.execute_input":"2023-12-03T13:22:50.509300Z","iopub.status.idle":"2023-12-03T13:22:50.518099Z","shell.execute_reply.started":"2023-12-03T13:22:50.509268Z","shell.execute_reply":"2023-12-03T13:22:50.517338Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Set up parameters\nbert_model_name = 'bert-base-cased'\nnum_classes = 2\nmax_length = 128\nbatch_size = 16\nnum_epochs = 2\nlearning_rate = 2e-5","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:55:29.830684Z","iopub.execute_input":"2023-12-03T15:55:29.831360Z","iopub.status.idle":"2023-12-03T15:55:29.835976Z","shell.execute_reply.started":"2023-12-03T15:55:29.831324Z","shell.execute_reply":"2023-12-03T15:55:29.834962Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:55:30.155934Z","iopub.execute_input":"2023-12-03T15:55:30.156550Z","iopub.status.idle":"2023-12-03T15:55:30.163488Z","shell.execute_reply.started":"2023-12-03T15:55:30.156516Z","shell.execute_reply":"2023-12-03T15:55:30.162590Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(bert_model_name)\ntrain_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\nval_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:55:30.354553Z","iopub.execute_input":"2023-12-03T15:55:30.354971Z","iopub.status.idle":"2023-12-03T15:55:30.810555Z","shell.execute_reply.started":"2023-12-03T15:55:30.354929Z","shell.execute_reply":"2023-12-03T15:55:30.809754Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = BERTClassifier(bert_model_name, num_classes).to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:25:42.548618Z","iopub.execute_input":"2023-12-03T16:25:42.549536Z","iopub.status.idle":"2023-12-03T16:25:43.655447Z","shell.execute_reply.started":"2023-12-03T16:25:42.549477Z","shell.execute_reply":"2023-12-03T16:25:43.654655Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=learning_rate)\ntotal_steps = len(train_dataloader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:25:44.792973Z","iopub.execute_input":"2023-12-03T16:25:44.794087Z","iopub.status.idle":"2023-12-03T16:25:44.802008Z","shell.execute_reply.started":"2023-12-03T16:25:44.794048Z","shell.execute_reply":"2023-12-03T16:25:44.801089Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    train(model, train_dataloader, optimizer, scheduler, device)\n    accuracy, report = evaluate(model, val_dataloader, device)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T16:25:45.116107Z","iopub.execute_input":"2023-12-03T16:25:45.116448Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/2\nValidation Accuracy: 0.6887\n              precision    recall  f1-score   support\n\n           0       0.72      0.73      0.72      2352\n           1       0.65      0.64      0.65      1879\n\n    accuracy                           0.69      4231\n   macro avg       0.68      0.68      0.68      4231\nweighted avg       0.69      0.69      0.69      4231\n\nEpoch 2/2\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"bert_classifier.pth\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}